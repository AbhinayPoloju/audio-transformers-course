# Hands-on exercise

This exercise is not graded and is intended to help you become familiar with the tools and libraries that you will be using throughout the rest of the course. If you are already experienced in using Google Colab, ðŸ¤— Datasets, librosa and ðŸ¤— Transformers, you may choose to skip this exercise.

1. Create a [Google Colab](https://colab.research.google.com) notebook.
2. Use ðŸ¤— Datasets to load the train split of the [`facebook/voxpopuli` dataset](https://huggingface.co/datasets/facebook/voxpopuli) in language of your choice in streaming mode.
3. Get the 3d example from the dataset and explore it. Given the features that this example has, what kinds of audio tasks can you use this dataset for?
4. Plot this example's waveform and spectrogram.
5. Go to [ðŸ¤— Hub](https://huggingface.co/datasets), explore pretrained models and find one that can be used for automatic speech recognition for the language that you have picked earlier. Instantiate a corresponding pipeline, and transcribe the example.
6. Compare the transcription that you get from the pipeline to the transcription provided in the example.

In the next chapters you'll learn more about various audio transformer architectures and will train your own model! 



