# Automatic speech recognition with a pipeline

Automatic Speech Recognition (ASR) is a task that involves transcribing speech audio recording into text.
This is a very useful task for a wide range of applications, such as virtual assistants, transcription services, and
language learning tools.

In this section, we'll use the `automatic-speech-recognition` pipeline to transcribe an audio recording of a person
asking a question about paying a bill:

```python
asr = pipeline("automatic-speech-recognition")
asr(minds[0]["audio"]["array"])
```

```out
{'text': 'I WOULD LIKE TO PAY MY ELECTRICITY BILL USING MY COD CAN YOU PLEASE ASSIST'}
```

The model seems to have done a pretty good job at transcribing the audio! It only got one word wrong ("card") compared
to the original transcription, which is pretty good considering the speaker has an Australian accent, where the letter "r"
is often silent. Having said that, I wouldn't recommend trying to pay your next electricity bill with a fish!

<Tip>

✏️ **Try it out!** Download another dialect or language of the MINDS-14 dataset and try transcribing some audio samples. For non-English audio, you will need to find an appropriate ASR model from the Hub. You can find a list of available models [here](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition).

</Tip>

Now that we've seen how to use pipelines for audio tasks, it's time to get our hands dirty and train our own models!
