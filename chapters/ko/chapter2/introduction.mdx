# 2단원. 오디오의 응용에 대한 소개[[Unit 2. A gentle introduction to audio applications]]

허깅페이스 오디오 코스의 두번째 단원에 오신것을 환영합니다! 지금까지는 오디오 데이터의 기본 개념을 살펴보고 🤗 Datasets과 🤗 Transformers 라이브러리를 활용해 오디오 데이터셋을 처리하는 방법을 배웠습니다. 또한 샘플링 속도, 진폭, 비트뎁스, 파형, 스펙트로그램, 사전학습된 모델을 위해 데이터를 전처리하는 방법에 관하여도 살펴봤습니다. 

이 시점에서 여러분은 🤗 Transformers로 처리할 수 있는 오디오 작업들에 관해 배우고 싶으실 것이며 이에 필요한 기초 지식은 모두 갖추셨을 것입니다. 몇 가지 놀라운 오디오 작업 예제들을 살펴봅시다:

* **오디오 분류(Audio classification)**: 오디오 클립을 쉽게 다른 카테고리들로 분류합니다. 녹음된 소리가 개가 짖는 소리인지 고양이가 우는 소리인지를 구분한다거나, 노래가 어떤 음악 장르에 속하는지 등을 판별합니다.
* **자동 음성 인식(Automatic speech recognition)**: 오디오 클립에서 자동으로 자막을 만듭니다. "오늘 하루 어때요?"와 같이 누군가가 말하는 녹음 내용을 텍스트로 변환할 수 있습니다. 메모를 할 때 상당히 유용합니다!
* **화자 구분(Speaker diarization)**: 녹음에서 누가 말하고 있는지 궁금했던 적이 있나요? 🤗 Transformers를 사용하면 오디오 클립의 어느 시점에 누가 말하는지를 구분할 수 있습니다. "Alice"와 "Bob" 두 사람의 대화 녹음에서 그들을 구분할 수 있다고 상상해 보세요.
* **텍스트 음성 변환(Text to speech)**: 텍스트의 나레이션을 만들어 오디오북을 만들거나 접근성(accessibility)을 향상시킬 수도 있고 게임의 NPC에게 목소리를 부여할 수도 있습니다. 🤗 Transformers를 사용하면 쉬운 일입니다!

이번 단원에서는 🤗 Transformers의 `pipeline()` 함수를 사용하여 이런 작업들에 사전학습된 모델을 쓰는 법을 알아보겠습니다.
특히, 사전학습된 모델이 오디오 분류와 자동 음성 인식에 어떻게 쓰이는지를 살펴보겠습니다.
시작해봅시다!
